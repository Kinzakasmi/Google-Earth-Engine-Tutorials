{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Earth Engine - Machine Learning Tutorial\n",
    "\n",
    "### This notebook is a Tutorial of how to use machine learning models in Google Earth Engine\n",
    "\n",
    "### Table of Contents\n",
    "* [I. Variables](#I.-Variables)\n",
    "* [II. Dataset](#II.-Dataset)\n",
    "* [III. Training](#III.-Training)\n",
    "* [IV. Evaluation](#IV.-Evaluation)\n",
    "* [V. Inference](#V.-Inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22999,
     "status": "ok",
     "timestamp": 1605869366847,
     "user": {
      "displayName": "Kinza kasmi",
      "photoUrl": "",
      "userId": "02164492479801566912"
     },
     "user_tz": -60
    },
    "id": "w0YZPnaQ6kxb",
    "outputId": "c6b079fd-ede5-413a-e4bb-89dbcc804d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/Colab Notebooks/Leakmited/france\n"
     ]
    }
   ],
   "source": [
    "#RUN ONLY IF IN GOOGLE COLAB ENVIRONMENT\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd gdrive/My Drive/Colab Notebooks/Leakmited/france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18367,
     "status": "ok",
     "timestamp": 1605869385223,
     "user": {
      "displayName": "Kinza kasmi",
      "photoUrl": "",
      "userId": "02164492479801566912"
     },
     "user_tz": -60
    },
    "id": "pfxVuecV6pQJ",
    "outputId": "6b482a67-1b79-4f78-daf8-5608d1d7506e"
   },
   "source": [
    "# Import, authenticate and initialize the Earth Engine library.\n",
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqsTf-SedQUa"
   },
   "source": [
    "# I. Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWYUuVHZdTfL"
   },
   "outputs": [],
   "source": [
    "start_date = \"2020-01-01\"\n",
    "end_date   = \"2020-12-31\"\n",
    "landsat    = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "sentinel   = ['VV','VH','VV_1','VH_1']\n",
    "bands      = landsat+sentinel\n",
    "scale      = 30\n",
    "nb_trees   = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucqlgKptcszM"
   },
   "source": [
    "# II. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gap4BiMUhz2R"
   },
   "source": [
    "First you will have to construct the dataset by using Google Earth Engine Code Editor.  \n",
    "Using the imagery as guidance, hover over the `Geometry Imports` box next to the geometry drawing tools and click `+ new layer`. Each new layer represents one class within the training data.  \n",
    "Let the first new layer represent `urban`. \n",
    "* Locate points in the new layer in urban or built up areas (buildings, roads, parking lots, etc.). \n",
    "* When finished collecting points, click `Exit` and configure the import (top of the script) as follows : \n",
    "  * Name the layer `urban` and click the icon to configure it. \n",
    "  * `Import as` FeatureCollection. \n",
    "  * `Add property` landcover and set its value to 2. (Subsequent classes will be 0 for field, 1 for forest, 3 for water) \n",
    "  * When finished, click `OK`  \n",
    "<img src=\"tuto_images/18.PNG\" width=500>\n",
    "* Export the Feature Collection to Assets by running the following on the Code Editor:\n",
    "  ```\n",
    "  Export.table.toAssets({\n",
    "    collection:urban,\n",
    "    description:'urban_pixels',\n",
    "    assetId:'urban})\n",
    "  ``` \n",
    "* Do the same for the other classes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndjWJ9DIPBy8"
   },
   "outputs": [],
   "source": [
    "def get_landsat(start_date,end_date):\n",
    "  def addQualityBands(image):\n",
    "    return image.addBands(image.metadata('system:time_start'))\n",
    "  collection = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "  collection = collection.filterDate(start_date,end_date).filterMetadata('CLOUD_COVER','less_than',0.3).map(addQualityBands)\n",
    "  image = collection.qualityMosaic('system:time_start').setDefaultProjection(collection.first().select(bands[0]).projection())\n",
    "  return image\n",
    "\n",
    "def get_sentinel1(start_date,end_date):\n",
    "  collection = ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
    "  collection = collection.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
    "  collection = collection.select('VV','VH').filterDate(start_date,end_date)\n",
    "  asc  = collection.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).median()\n",
    "  desc = collection.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).median()\n",
    "  image = ee.Image.cat([asc,desc])\n",
    "  image = image.clamp(-50,1).subtract(-50).divide(51).setDefaultProjection(collection.first().projection())\n",
    "  return image\n",
    "\n",
    "def get_image(start_date,end_date,landsat_bands,sentinel1_bands):\n",
    "  landsat = get_landsat(start_date,end_date)\n",
    "  sentinel = get_sentinel1(start_date,end_date)\n",
    "  image = ee.Image.cat([landsat.select(landsat_bands),sentinel.select(sentinel1_bands)])\n",
    "  return image\n",
    "\n",
    "def get_labels():  \n",
    "  field = ee.FeatureCollection('users/leakm/field')\n",
    "  forest = ee.FeatureCollection('users/leakm/forest')\n",
    "  urbain = ee.FeatureCollection('users/leakm/urbain')\n",
    "  water = ee.FeatureCollection('users/leakm/water')\n",
    "  labels = field.merge(forest).merge(urbain).merge(water)\n",
    "  return labels\n",
    "  \n",
    "def get_training_data(image,labels,scale):\n",
    "  #Sample the input imagery to get a FeatureCollection of training data.\n",
    "  training = image.sampleRegions(\n",
    "    collection = labels,\n",
    "    properties = ['landcover'],\n",
    "    tileScale  = 8,\n",
    "    scale      = scale)\n",
    "  return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9fk1ftDoCCN"
   },
   "outputs": [],
   "source": [
    "image = get_image(start_date,end_date,landsat,sentinel)\n",
    "labels = get_labels()\n",
    "training = get_training_data(image,labels,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KMHJ-2xc9pI"
   },
   "source": [
    "# III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VKE8BvYdIjE"
   },
   "outputs": [],
   "source": [
    "def train(training,bands,nb_trees):\n",
    "  rf = ee.Classifier.smileRandomForest(numberOfTrees=nb_trees)\n",
    "  classifier = rf.train(\n",
    "    features        = training,\n",
    "    classProperty   = 'landcover',\n",
    "    inputProperties = bands\n",
    "  )\n",
    "  confusion_matrix = classifier.confusionMatrix()\n",
    "  print('RF error matrix: ', confusion_matrix.getInfo())\n",
    "  print('RF accuracy: ', confusion_matrix.accuracy().getInfo())\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYjskvkmdAZO"
   },
   "outputs": [],
   "source": [
    "classifier = train(training,bands,nb_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQj0j5kZdK2c"
   },
   "source": [
    "# IV. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EByNpGnTgsI5"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(image,classifier,nlcd,scale):\n",
    "  evaluation = image.addBands(nlcd).sample(region=nlcd.geometry().bounds(),numPixels = 1000,seed = 0,scale=scale)\n",
    "  evaluated = evaluation.classify(classifier)\n",
    "  testAccuracy = evaluated.errorMatrix('true_landcover', 'classification')\n",
    "  print('Validation error matrix: ', testAccuracy.getInfo())\n",
    "  print('Validation overall accuracy: ', testAccuracy.accuracy().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kYB6BQ4gxOd"
   },
   "outputs": [],
   "source": [
    "# Use a known dataset of labels if you don't want to construct the evaluation dataset by hand\n",
    "nlcd = ee.Image('users/leakm/france2017').select('b1').remap([42,41,43,44,31,32,221,222,11,12,34,36,211,45,46,51,53],[2,2,2,2,1,1,0,0,0,0,0,0,0,3,0,3,3]).rename('landcover')\n",
    "evaluate_model(image,classifier,nlcd,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmH3K_uUg0HO"
   },
   "source": [
    "# V. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9o-gVB7dcy2N"
   },
   "outputs": [],
   "source": [
    "def infere(image,region,classifier):\n",
    "  #Classify the input imagery.\n",
    "  classified = image.clip(region.bounds()).classify(classifier)\n",
    "  return classified,pipeline\n",
    "\n",
    "def display(Map,classified,pipeline):\n",
    "  #Define a palette for the Land Use classification.\n",
    "  palette = [\n",
    "    '008000', #  field (0) // green\n",
    "    'D3D3D3', # forest (1)  // grey\n",
    "    'FF0000', # urbain (2)  // red\n",
    "    '0000FF'  # water (3)  // blue\n",
    "  ]\n",
    "  Map.addLayer(classified, {'min': 0, 'max': 2, 'palette': palette}, 'Land Use Classification')\n",
    "\n",
    "def export_inference(classified,name,pipeline,scale):\n",
    "  task = ee.batch.Export.image.toDrive(\n",
    "    image          = classified,\n",
    "    description    = name,\n",
    "    region         = pipeline.geometry().bounds(),\n",
    "    scale          = scale,\n",
    "    fileNamePrefix = name\n",
    "  )\n",
    "  task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnR5z_-SchTT"
   },
   "outputs": [],
   "source": [
    "# Define your region here by writing ee.Geometry... \n",
    "# for example region = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax]) with geospatial coordinates\n",
    "# or region = ee.Geometry.Point([lon,lat]).buffer(radius) with radius in meters\n",
    "region = ee.Geometry.Point([lon,lat]).buffer(radius)\n",
    "# Inference\n",
    "classified,pipeline = infere(image,region,classifier)\n",
    "\n",
    "#Export inference as TIF to Drive\n",
    "export_inference(classified,name+'water',pipeline,scale)\n",
    "\n",
    "#Visualise inference on the Map\n",
    "import geemap.efolium as gmap\n",
    "Map = gmap.Map()\n",
    "display_water(Map,classified,pipeline)\n",
    "Map"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOY+isCEbb9WcwYLz4F5yc5",
   "collapsed_sections": [],
   "name": "EE_land_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
